{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naturalsolutions/3m-ml-data-preparation/blob/main/3m_landcover_ai_data_preparation_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjKo1Wa6Sup1"
      },
      "source": [
        "# Depedencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZLRDRLrS6A6",
        "outputId": "1083687f-e9ee-4b27-911f-290415abf75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rasterio in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (1.3.9)\n",
            "Requirement already satisfied: affine in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio) (2023.11.17)\n",
            "Requirement already satisfied: click>=4.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio) (1.26.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio) (65.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "\u001b[33mDEPRECATION: geopolars 0.1.0a4 has a non-standard dependency specifier pyarrow>=4.0.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of geopolars or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: geocube in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (0.4.2)\n",
            "Requirement already satisfied: appdirs in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (1.4.4)\n",
            "Requirement already satisfied: click>=6.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (8.1.7)\n",
            "Requirement already satisfied: geopandas>=0.7 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (0.14.1)\n",
            "Requirement already satisfied: odc-geo in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (0.4.1)\n",
            "Requirement already satisfied: rasterio in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (1.3.9)\n",
            "Requirement already satisfied: rioxarray>=0.4 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (0.15.0)\n",
            "Requirement already satisfied: scipy in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (1.11.4)\n",
            "Requirement already satisfied: xarray>=0.17 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (2023.12.0)\n",
            "Requirement already satisfied: pyproj>=2 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geocube) (1.26.2)\n",
            "Requirement already satisfied: fiona>=1.8.21 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geopandas>=0.7->geocube) (1.9.5)\n",
            "Requirement already satisfied: packaging in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geopandas>=0.7->geocube) (23.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geopandas>=0.7->geocube) (2.1.4)\n",
            "Requirement already satisfied: shapely>=1.8.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geopandas>=0.7->geocube) (2.0.2)\n",
            "Requirement already satisfied: certifi in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pyproj>=2->geocube) (2023.11.17)\n",
            "Requirement already satisfied: affine in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio->geocube) (2.4.0)\n",
            "Requirement already satisfied: attrs in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio->geocube) (23.1.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio->geocube) (0.7.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio->geocube) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio->geocube) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from rasterio->geocube) (65.5.0)\n",
            "Requirement already satisfied: cachetools in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from odc-geo->geocube) (5.3.2)\n",
            "Requirement already satisfied: six in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas>=0.7->geocube) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas>=0.7->geocube) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas>=0.7->geocube) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas>=0.7->geocube) (2023.3)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from snuggs>=1.4.1->rasterio->geocube) (3.1.1)\n",
            "\u001b[33mDEPRECATION: geopolars 0.1.0a4 has a non-standard dependency specifier pyarrow>=4.0.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of geopolars or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: pandas in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas) (1.26.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "\u001b[33mDEPRECATION: geopolars 0.1.0a4 has a non-standard dependency specifier pyarrow>=4.0.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of geopolars or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: geopandas in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (0.14.1)\n",
            "Requirement already satisfied: fiona>=1.8.21 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geopandas) (1.9.5)\n",
            "Requirement already satisfied: packaging in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geopandas) (23.2)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geopandas) (2.1.4)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geopandas) (3.6.1)\n",
            "Requirement already satisfied: shapely>=1.8.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from geopandas) (2.0.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.1.0)\n",
            "Requirement already satisfied: certifi in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2023.11.17)\n",
            "Requirement already satisfied: click~=8.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
            "Requirement already satisfied: six in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (65.5.0)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (1.26.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
            "\u001b[33mDEPRECATION: geopolars 0.1.0a4 has a non-standard dependency specifier pyarrow>=4.0.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of geopolars or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: shapely in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (2.0.2)\n",
            "Requirement already satisfied: numpy>=1.14 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from shapely) (1.26.2)\n",
            "\u001b[33mDEPRECATION: geopolars 0.1.0a4 has a non-standard dependency specifier pyarrow>=4.0.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of geopolars or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Collecting h5\n",
            "  Downloading h5-0.9.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: h5py>=3.7.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from h5) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from h5) (1.26.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.5.0 in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (from h5) (4.8.0)\n",
            "Downloading h5-0.9.2-py3-none-any.whl (16 kB)\n",
            "\u001b[33mDEPRECATION: geopolars 0.1.0a4 has a non-standard dependency specifier pyarrow>=4.0.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of geopolars or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: h5\n",
            "Successfully installed h5-0.9.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: numpy in /Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages (1.26.2)\n",
            "\u001b[33mDEPRECATION: geopolars 0.1.0a4 has a non-standard dependency specifier pyarrow>=4.0.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of geopolars or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio\n",
        "!pip install geocube\n",
        "!pip install pandas\n",
        "!pip install geopandas\n",
        "!pip install shapely\n",
        "!pip install h5\n",
        "!pip install numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcls9OZkwuv3",
        "outputId": "cf355ac4-db97-4b7a-c46a-b8ca09509b34"
      },
      "outputs": [],
      "source": [
        "# Running in Colab ? Mounting drive and set working directory\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "WORKDIR = \"/content/drive/MyDrive/3m-ai/grid_256px_11_classes\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# As an alternative, work locally\n",
        "WORKDIR = \"./3m-ai/grid_256px_11_classes\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdED5BYQSup6"
      },
      "source": [
        "# Utils functions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvVk9avjSup6"
      },
      "source": [
        "### - Grid factories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "-UzzQoDeSup7"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "# from pandera.typing import Index, DataFrame, Series\n",
        "# from pandera.typing.geopandas import GeoDataFrame, GeoSeries\n",
        "# import pandera as pa\n",
        "\n",
        "\n",
        "def create_grid(\n",
        "    gdf: None,\n",
        "    bounds: List[float] | None = None,\n",
        "    n_cells=10,\n",
        "    overlap=False,\n",
        "    crs=\"EPSG:4326\",\n",
        "):\n",
        "    \"\"\"Create square grid that covers a geodataframe area\n",
        "    or a fixed boundary with x-y coords\n",
        "    returns: a GeoDataFrame of grid polygons\n",
        "    see https://james-brennan.github.io/posts/fast_gridding_geopandas/\n",
        "    \"\"\"\n",
        "\n",
        "    import geopandas as gpd\n",
        "    import shapely\n",
        "    import numpy as np\n",
        "\n",
        "    if bounds != None:\n",
        "        xmin, ymin, xmax, ymax = bounds\n",
        "    else:\n",
        "        xmin, ymin, xmax, ymax = gdf.total_bounds\n",
        "\n",
        "    # get cell size\n",
        "    cell_size = (xmax - xmin) / n_cells\n",
        "    # create the cells in a loop\n",
        "    grid_cells = []\n",
        "    for x0 in np.arange(xmin, xmax + cell_size, cell_size):\n",
        "        for y0 in np.arange(ymin, ymax + cell_size, cell_size):\n",
        "            x1 = x0 - cell_size\n",
        "            y1 = y0 + cell_size\n",
        "            poly = shapely.geometry.box(x0, y0, x1, y1)\n",
        "            # print (gdf.overlay(poly, how='intersection'))\n",
        "            grid_cells.append(poly)\n",
        "\n",
        "    cells = gpd.GeoDataFrame(grid_cells, columns=[\"geometry\"], crs=crs)\n",
        "    if overlap == True:\n",
        "        cols = [\"grid_id\", \"geometry\", \"grid_area\"]\n",
        "        cells = cells.sjoin(gdf, how=\"inner\").drop_duplicates(\"geometry\")\n",
        "    return cells\n",
        "\n",
        "\n",
        "def create_hex_grid(gdf=None, bounds=None, n_cells=10, overlap=False, crs=\"EPSG:4326\"):\n",
        "    \"\"\"Hexagonal grid over geometry.\n",
        "    See https://sabrinadchan.github.io/data-blog/building-a-hexagonal-cartogram.html\n",
        "    \"\"\"\n",
        "\n",
        "    from shapely.geometry import Polygon\n",
        "    import geopandas as gpd\n",
        "    import numpy as np\n",
        "\n",
        "    if bounds != None:\n",
        "        xmin, ymin, xmax, ymax = bounds\n",
        "    else:\n",
        "        xmin, ymin, xmax, ymax = gdf.total_bounds\n",
        "\n",
        "    unit = (xmax - xmin) / n_cells\n",
        "    a = np.sin(np.pi / 3)\n",
        "    cols = np.arange(np.floor(xmin), np.ceil(xmax), 3 * unit)\n",
        "    rows = np.arange(np.floor(ymin) / a, np.ceil(ymax) / a, unit)\n",
        "\n",
        "    # print (len(cols))\n",
        "    hexagons = []\n",
        "    for x in cols:\n",
        "        for i, y in enumerate(rows):\n",
        "            if i % 2 == 0:\n",
        "                x0 = x\n",
        "            else:\n",
        "                x0 = x + 1.5 * unit\n",
        "\n",
        "            hexagons.append(\n",
        "                Polygon(\n",
        "                    [\n",
        "                        (x0, y * a),\n",
        "                        (x0 + unit, y * a),\n",
        "                        (x0 + (1.5 * unit), (y + unit) * a),\n",
        "                        (x0 + unit, (y + (2 * unit)) * a),\n",
        "                        (x0, (y + (2 * unit)) * a),\n",
        "                        (x0 - (0.5 * unit), (y + unit) * a),\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "\n",
        "    grid = gpd.GeoDataFrame({\"geometry\": hexagons}, crs=crs)\n",
        "    grid[\"grid_area\"] = grid.area\n",
        "    grid = grid.reset_index().rename(columns={\"index\": \"grid_id\"})\n",
        "    if overlap == True:\n",
        "        cols = [\"grid_id\", \"geometry\", \"grid_area\"]\n",
        "        grid = grid.sjoin(gdf, how=\"inner\").drop_duplicates(\"geometry\")\n",
        "    return grid\n",
        "\n",
        "\n",
        "def create_size_based_grid(\n",
        "    gdf: None,\n",
        "    bounds: List[float] | None = None,\n",
        "    size=256,\n",
        "    predicate=\"within\",\n",
        "    crs=\"EPSG:2154\",\n",
        "    epsg: int | None = None,\n",
        "):\n",
        "    \"\"\"Create square grid of fixed size (beware of crs unit) that covers a geodataframe area\n",
        "    or a fixed boundary with x-y coords\n",
        "    returns: a GeoDataFrame of grid polygons\n",
        "    \"\"\"\n",
        "    from shapely import Polygon\n",
        "    from geopandas import GeoDataFrame, sjoin\n",
        "    from numpy import arange\n",
        "\n",
        "    gdf_to_merge = gdf\n",
        "    gdf_to_merge[\"merge\"] = 1\n",
        "    gdf_merged = gdf_to_merge.dissolve(\"merge\")\n",
        "\n",
        "    if bounds != None:\n",
        "        xmin, ymin, xmax, ymax = bounds\n",
        "    else:\n",
        "        xmin, ymin, xmax, ymax = gdf_merged.total_bounds\n",
        "\n",
        "    cols = list(arange(xmin, xmax + size, size))\n",
        "    rows = list(arange(ymin, ymax + size, size))\n",
        "\n",
        "    polygons = []\n",
        "    for x in cols[:-1]:\n",
        "        for y in rows[:-1]:\n",
        "            polygons.append(\n",
        "                Polygon(\n",
        "                    [\n",
        "                        (x, y),\n",
        "                        (x + size, y),\n",
        "                        (x + size, y + size),\n",
        "                        (x, y + size),\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "    if epsg != None:\n",
        "        grid = GeoDataFrame({\"geometry\": polygons}, epsg=epsg)\n",
        "    else:\n",
        "        grid = GeoDataFrame({\"geometry\": polygons}, crs=crs)\n",
        "    if predicate != None:\n",
        "        grid = sjoin(grid, gdf_merged, how=\"inner\", predicate=predicate)\n",
        "    grid.insert(1, \"id\", range(1, 1 + len(grid)))\n",
        "    grid = grid.reset_index()\n",
        "    grid = grid[[\"id\", \"geometry\"]]\n",
        "    return grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN79tLXeSup7"
      },
      "source": [
        "### - Geoportail webservices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "0b2cAtL1Sup8"
      },
      "outputs": [],
      "source": [
        "from typing import Union, List\n",
        "\n",
        "Num = Union[int, float]\n",
        "\n",
        "\n",
        "def stringify_bbox(bounds: List[Num]) -> str:\n",
        "    \"\"\"\n",
        "    Receive bounding box as a list and return it as a formatted string\n",
        "    \"\"\"\n",
        "    xmin, ymin, xmax, ymax = bounds\n",
        "    return f\"{xmin},{ymin},{xmax},{ymax}\"\n",
        "\n",
        "\n",
        "def get_tile_url(\n",
        "    base_url=\"https://wxs.ign.fr/ortho/geoportail/r/wms\",\n",
        "    layer_name=\"ORTHOIMAGERY.ORTHOPHOTOS.BDORTHO\",\n",
        "    bbox=\"785802.3085941937752,6336806.404346071184,786208.1537742479704,6337311.468582574278\",\n",
        "    size=256,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Helper to format geoservices web expert URL\n",
        "\n",
        "    Args:\n",
        "      base_url:  \"https://wxs.ign.fr/ortho/geoportail/r/wms\" | \"https://wxs.ign.fr/orthohisto/geoportail/r/wms\"\n",
        "      layer_name: layer service; see IGN geoservices doc for details:\n",
        "              - Ortho https://geoservices.ign.fr/services-web-experts-ortho\n",
        "              - Orthohisto https://geoservices.ign.fr/services-web-experts-orthohisto\n",
        "      bbox: bounding box param, see `stringify_bbox` function to get formatted parrams from geopandas bounding box\n",
        "\n",
        "    Returns:\n",
        "      Formatted URI with params\n",
        "    \"\"\"\n",
        "    params = f\"SERVICE=WMS&VERSION=1.3.0&REQUEST=GetMap&BBOX={bbox}&CRS=EPSG:2154&WIDTH={size}&HEIGHT={size}&LAYERS={layer_name}&STYLES=&FORMAT=image/geotiff&DPI=72&MAP_RESOLUTION=72&FORMAT_OPTIONS=dpi:72\"\n",
        "    return f\"{base_url}?{params}\"\n",
        "\n",
        "\n",
        "def download_image_from_url(\n",
        "    url=None, index=None, out_path=\"./downloads/tiles\", default_images_folder=\"default\"\n",
        "):\n",
        "    import time\n",
        "    from urllib.parse import urlparse, parse_qs\n",
        "    import requests\n",
        "    import os\n",
        "\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    if url is None:\n",
        "        raise ValueError(\"url param s required\")\n",
        "    t0 = time.time()\n",
        "    parsed_url = urlparse(url)\n",
        "    layer_param = parse_qs(parsed_url.query)[\"LAYERS\"][0]\n",
        "    bbox_param = parse_qs(parsed_url.query)[\"BBOX\"][0]\n",
        "    bbox_tuple = tuple(map(float, bbox_param.split(\",\")))\n",
        "\n",
        "    if layer_param in [\n",
        "        \"ORTHOIMAGERY.ORTHOPHOTOS.IRC\",\n",
        "        \"ORTHOIMAGERY.ORTHOPHOTOS.IRC-EXPRESS.2021\",\n",
        "    ]:\n",
        "        out_dir = f\"{out_path}/irc\"\n",
        "    elif layer_param in [\n",
        "        \"ORTHOIMAGERY.ORTHOPHOTOS.BDORTHO\",\n",
        "        \"ORTHOIMAGERY.ORTHOPHOTOS.ORTHO-EXPRESS.2021\",\n",
        "    ]:\n",
        "        out_dir = f\"{out_path}/ortho\"\n",
        "    else:\n",
        "        out_dir = f\"{out_path}/{default_images_folder}\"\n",
        "\n",
        "    if not os.path.exists(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "    try:\n",
        "        r = requests.get(url)\n",
        "        if r.status_code == 200:\n",
        "            if index is None:\n",
        "                image_path = f\"{out_dir}/image_{hash(bbox_tuple)}.tiff\"\n",
        "            else:\n",
        "                image_path = f\"{out_dir}/image_{index}.tiff\"\n",
        "            with open(image_path, \"wb\") as f:\n",
        "                f.write(r.content)\n",
        "            return (image_path, time.time() - t0, url)\n",
        "        else:\n",
        "            return (None, None, url)\n",
        "    except Exception as e:\n",
        "        print(\"Exception in download_url():\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMAjQSM3Sup9"
      },
      "source": [
        "### - Plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "dgJB1My6Sup-"
      },
      "outputs": [],
      "source": [
        "def plot_trio(ortho, irc, mask):\n",
        "    import rasterio\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Paths to the three raster images\n",
        "    image_paths = [ortho, irc, mask]\n",
        "\n",
        "    # Create a figure with three subplots\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Loop through the image paths and plot each image\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        with rasterio.open(image_path) as src:\n",
        "            # Read the image data\n",
        "            img_data = src.read()\n",
        "\n",
        "            # Plot the image using imshow\n",
        "            axes[i].imshow(\n",
        "                img_data.transpose((1, 2, 0))\n",
        "            )  # Transpose to (height, width, bands) for RGB images\n",
        "            axes[i].set_title(f\"Image {i + 1}\")\n",
        "\n",
        "    # Adjust layout and show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_trio_from_index(index, dataset_path=\"./datasets\"):\n",
        "    import rasterio\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Paths to the three raster images\n",
        "    image_paths = [\n",
        "        f\"{dataset_path}/images/ortho/image_{index}.tiff\",\n",
        "        f\"{dataset_path}/images/irc/image_{index}.tiff\",\n",
        "        f\"{dataset_path}/masks/mask_{index}.tif\",\n",
        "    ]\n",
        "\n",
        "    # Create a figure with three subplots\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Loop through the image paths and plot each image\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        with rasterio.open(image_path) as src:\n",
        "            # Read the image data\n",
        "            img_data = src.read()\n",
        "\n",
        "            # Plot the image using imshow\n",
        "            axes[i].imshow(\n",
        "                img_data.transpose((1, 2, 0))\n",
        "            )  # Transpose to (height, width, bands) for RGB images\n",
        "            axes[i].set_title(f\"Image {i + 1}\")\n",
        "\n",
        "    # Adjust layout and show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_area_and_grid(area_gdf, grid_gdf, title=\"Geoplot 1\"):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "    area_gdf.plot(ec=\"gray\", fc=\"none\", figsize=(10, 10), ax=ax)\n",
        "    grid_gdf.plot(fc=\"none\", ec=\"black\", ax=ax)\n",
        "    ax.set_title(title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNTWLy8sSup_"
      },
      "source": [
        "### - Data transformation utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "uiXNE1FFSup_"
      },
      "outputs": [],
      "source": [
        "def labels_to_mask_with_geocube(\n",
        "    gdf, index, size=256, resolution=1, out_path=\"./datasets/masks\"\n",
        "):\n",
        "    from geocube.api.core import make_geocube\n",
        "    import os\n",
        "\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    # Using GeoCube to rasterize the Vector\n",
        "    mask_geocube = make_geocube(\n",
        "        vector_data=gdf,\n",
        "        measurements=[\"eunis_niv1_label\"],\n",
        "        resolution=(-resolution, resolution),\n",
        "        fill=0,\n",
        "    )\n",
        "    reduced_data = mask_geocube.isel(x=slice(256), y=slice(256))\n",
        "    new_da = reduced_data[\"eunis_niv1_label\"].astype(\"int8\")\n",
        "    new_da\n",
        "    # Save raster census raster\n",
        "    new_da.rio.to_raster(f\"{out_path}/mask_{index}.tif\")\n",
        "    return f\"{out_path}/mask_{index}.tif\"\n",
        "\n",
        "\n",
        "# TODO: refact this function to allow multithread processing\n",
        "def create_4_band_training_raster(gdf, index, out_path=\"./datasets/images\"):\n",
        "    import rasterio\n",
        "    from rasterio.plot import reshape_as_raster, reshape_as_image\n",
        "    import os\n",
        "\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    (minx, miny, maxx, maxy) = gdf.total_bounds\n",
        "    ortho_url = get_tile_url(\n",
        "        base_url=\"https://wxs.ign.fr/orthohisto/geoportail/r/wms\",\n",
        "        layer_name=\"ORTHOIMAGERY.ORTHOPHOTOS.ORTHO-EXPRESS.2021\",\n",
        "        bbox=f\"{minx},{miny},{maxx},{maxy}\",\n",
        "    )\n",
        "    irc_url = get_tile_url(\n",
        "        base_url=\"https://wxs.ign.fr/orthohisto/geoportail/r/wms\",\n",
        "        layer_name=\"ORTHOIMAGERY.ORTHOPHOTOS.IRC-EXPRESS.2021\",\n",
        "        bbox=f\"{minx},{miny},{maxx},{maxy}\",\n",
        "    )\n",
        "\n",
        "    if not os.path.exists(\"./datasets/images\"):\n",
        "        os.makedirs(\"./datasets/images\")\n",
        "\n",
        "    (ortho_path, ortho_time, d_ortho_url) = download_image_from_url(\n",
        "        url=ortho_url, index=index, out_path=out_path\n",
        "    )\n",
        "    (irc_path, irc_time, d_irc_url) = download_image_from_url(\n",
        "        url=irc_url, index=index, out_path=out_path\n",
        "    )\n",
        "    train_dir = f\"{out_path}/rgbn\"\n",
        "    if not os.path.exists(train_dir):\n",
        "        os.makedirs(train_dir)\n",
        "\n",
        "    train_path = f\"{train_dir}/image_{index}.tif\"\n",
        "    # Open the RGB image\n",
        "    with rasterio.open(ortho_path) as rgb_src:\n",
        "        # Read RGB data and metadata\n",
        "        rgb_data = rgb_src.read()\n",
        "        metadata = rgb_src.meta.copy()\n",
        "\n",
        "    # Open the nir image\n",
        "    with rasterio.open(irc_path) as infrared_src:\n",
        "        # Read infrared data\n",
        "        infrared_data = infrared_src.read(1)\n",
        "\n",
        "    # Combine RGB and infrared data into a four-band array\n",
        "    four_band_data = [rgb_data[0], rgb_data[1], rgb_data[2], infrared_data]\n",
        "    # Update metadata for the new four-band raster\n",
        "    metadata.update(count=4)\n",
        "\n",
        "    # Create a new raster file and write the four-band data\n",
        "    with rasterio.open(train_path, \"w\", **metadata) as dst:\n",
        "        for i, band in enumerate(four_band_data, start=1):\n",
        "            dst.write(band, i)\n",
        "\n",
        "    return (ortho_path, irc_path, train_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9aVuSmHSuqA"
      },
      "source": [
        "# Data preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVTX97MTSuqA"
      },
      "source": [
        "### Remote source files links\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "mvlbG6JKSuqA"
      },
      "outputs": [],
      "source": [
        "# Liens data.montpellier3m.fr\n",
        "poles_zonage_3m_url = \"https://data.montpellier3m.fr/sites/default/files/ressources/MMM_MMM_PolesZonage_0.zip\"\n",
        "\n",
        "# cadastre archive contains multiple shapefiles (hydro, bati...)\n",
        "cadastre_3m_url = (\n",
        "    \"https://data.montpellier3m.fr/sites/default/files/ressources/MMM_MMM_Cadastre.zip\"\n",
        ")\n",
        "contour_3m_url = (\n",
        "    \"https://data.montpellier3m.fr/sites/default/files/ressources/MMM_MMM_Contours.zip\"\n",
        ")\n",
        "occsol_3m_url = (\n",
        "    \"https://data.montpellier3m.fr/sites/default/files/ressources/MMM_MMM_OccupSol.zip\"\n",
        ")\n",
        "vegetation_fine_3m = (\n",
        "    \"https://data.montpellier3m.fr/sites/default/files/ressources/MMM_MMM_VegFine.zip\"\n",
        ")\n",
        "\n",
        "\n",
        "def download_extract_delete_remote_archives(archives_urls, out_folder=\"./data/3m\"):\n",
        "    import os\n",
        "    import requests\n",
        "    import zipfile\n",
        "\n",
        "    if not os.path.exists(out_folder):\n",
        "        os.makedirs(out_folder)\n",
        "\n",
        "    # Download the archive ; to do serialize this\n",
        "    for index, url in enumerate(archives_urls):\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Check if the request was successful (status code 200)\n",
        "        if response.status_code == 200:\n",
        "            # Get the filename from the response headers\n",
        "            content_disposition = response.headers.get(\"Content-Disposition\")\n",
        "            if content_disposition:\n",
        "                filename = content_disposition.split(\"filename=\")[1].strip('\"')\n",
        "            else:\n",
        "                # If no filename is provided in the headers, the endtrail of url\n",
        "                filename = url.split(\"/\")[-1]\n",
        "\n",
        "            # Create the path for the downloaded archive\n",
        "            archive_path = os.path.join(\n",
        "                out_folder, filename\n",
        "            )  # Adjust for different archive types\n",
        "\n",
        "            # Save the downloaded content to the archive file\n",
        "            with open(archive_path, \"wb\") as archive_file:\n",
        "                archive_file.write(response.content)\n",
        "\n",
        "            # Extract the archive\n",
        "            extract_folder = os.path.join(\n",
        "                out_folder, os.path.splitext(os.path.basename(archive_path))[0]\n",
        "            )\n",
        "            with zipfile.ZipFile(archive_path, \"r\") as zip_ref:\n",
        "                zip_ref.extractall(extract_folder)\n",
        "\n",
        "            # Optionally, delete the downloaded archive\n",
        "            os.remove(archive_path)\n",
        "\n",
        "            print(\n",
        "                f\"Archive downloaded, extracted, and deleted successfully to: {extract_folder}\"\n",
        "            )\n",
        "        else:\n",
        "            print(f\"Failed to download archive. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfJM0sRBSuqA",
        "outputId": "b79cc2da-e857-4cb0-bc0e-146c41b33a2d"
      },
      "outputs": [],
      "source": [
        "# Download resource files\n",
        "download_extract_delete_remote_archives(\n",
        "    archives_urls=[poles_zonage_3m_url, contour_3m_url, occsol_3m_url],\n",
        "    out_folder=f\"{WORKDIR}/data/test\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "1-d1inAdSuqB"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "\n",
        "# Get administrative bondaries for study area (3Md)\n",
        "boundaries = gpd.read_file(\n",
        "    \"./data/test/MMM_MMM_PolesZonage_0/MMM_MMM_PolesZonage.shp\", crs=\"EPSG:2154\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "L70NUuq_SuqB"
      },
      "outputs": [],
      "source": [
        "#### (optionnal) create parquet files for big geospatial data (>100Mb) to speed data reads + transformations\n",
        "import os\n",
        "\n",
        "# Landcover (occsol) to parquet file\n",
        "occsol_gdf = gpd.read_file(\n",
        "    f\"{WORKDIR}/data/test/MMM_MMM_OccupSol/MMM_MMM_OccupSol.shp\", crs=\"EPSG:2154\"\n",
        ")\n",
        "if not os.path.exists(f\"{WORKDIR}/data/parquet\"):\n",
        "    os.makedirs(f\"{WORKDIR}/data/parquet\")\n",
        "occsol_gdf.to_parquet(f\"{WORKDIR}/data/parquet/clc_3m.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "4jLtrn4FSuqB"
      },
      "outputs": [],
      "source": [
        "# occsol dataframe preparation\n",
        "clc_3m_gdf = gpd.read_parquet(f\"{WORKDIR}/data/parquet/clc_3m.parquet\")\n",
        "clc_3m_gdf.to_crs(\"EPSG:2154\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uP_xj0DSSuqB",
        "outputId": "e0b5df69-62a6-45e9-c432-0c11206df263"
      },
      "outputs": [],
      "source": [
        "# Create a grid for SA entire coverage\n",
        "grid_3m = create_size_based_grid(gdf=clc_3m_gdf)\n",
        "grid_3m[\"size\"] = grid_3m[\"geometry\"].length / 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "QDGIl9dASuqB",
        "outputId": "7751076b-fcd3-44ca-91a6-1760852ac5ee"
      },
      "outputs": [],
      "source": [
        "# Uncomment this, if you want plot 3M grid and landcover layer (be patient...)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
        "# axs = ax.flat\n",
        "# clc_3m_gdf.plot(ec=\"gray\", fc=\"none\", figsize=(10, 10), ax=axs[0])\n",
        "# grid_3m.plot(fc=\"none\", ec=\"black\", ax=axs[1])\n",
        "# axs[0].axis(\"off\")\n",
        "# axs[1].axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4zWqDM4NSuqC",
        "outputId": "4cb4f816-dbba-4041-e5ec-920bdfce08e6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c2021_niv1</th>\n",
              "      <th>lib21_niv1</th>\n",
              "      <th>c2021_niv4</th>\n",
              "      <th>lib21_niv4</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>Espaces naturels non bois√©s</td>\n",
              "      <td>7820</td>\n",
              "      <td>Marais maritimes</td>\n",
              "      <td>POLYGON ((742269.535 6248240.552, 742250.300 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5121</td>\n",
              "      <td>Espaces libres urbains</td>\n",
              "      <td>POLYGON ((783953.823 6291883.226, 783966.394 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5121</td>\n",
              "      <td>Espaces libres urbains</td>\n",
              "      <td>POLYGON ((781205.235 6284279.038, 781260.980 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>Eau</td>\n",
              "      <td>8220</td>\n",
              "      <td>Plans d'eau et lagunes littorales</td>\n",
              "      <td>POLYGON ((780145.613 6277024.020, 780063.022 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5121</td>\n",
              "      <td>Espaces libres urbains</td>\n",
              "      <td>POLYGON ((758879.856 6272901.789, 758892.140 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5221</td>\n",
              "      <td>Vergers en exploitation</td>\n",
              "      <td>POLYGON ((785921.828 6282821.166, 785954.456 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5221</td>\n",
              "      <td>Vergers en exploitation</td>\n",
              "      <td>POLYGON ((760408.100 6274080.600, 760403.112 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>Espaces bois√©s</td>\n",
              "      <td>6110</td>\n",
              "      <td>Feuillus m√©sophiles dominants</td>\n",
              "      <td>POLYGON ((744068.463 6254143.414, 744011.575 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Eau</td>\n",
              "      <td>8300</td>\n",
              "      <td>Mer, oc√©an et estuaires</td>\n",
              "      <td>POLYGON ((757311.864 6255758.885, 757309.379 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5140</td>\n",
              "      <td>Prairies</td>\n",
              "      <td>POLYGON ((758260.437 6271489.652, 758257.173 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>8</td>\n",
              "      <td>Eau</td>\n",
              "      <td>8210</td>\n",
              "      <td>Plans d‚Äôeau douce</td>\n",
              "      <td>POLYGON ((750614.887 6272923.560, 750660.415 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5131</td>\n",
              "      <td>Cultures annuelles</td>\n",
              "      <td>POLYGON ((762779.796 6271812.527, 762813.156 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5140</td>\n",
              "      <td>Prairies</td>\n",
              "      <td>POLYGON ((756135.058 6270198.722, 756115.697 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>Surfaces industrielles ou commerciales et infr...</td>\n",
              "      <td>2111</td>\n",
              "      <td>Zones industrielles</td>\n",
              "      <td>POLYGON ((770134.885 6275211.804, 770099.111 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5211</td>\n",
              "      <td>Vignes en exploitation</td>\n",
              "      <td>POLYGON ((783495.201 6299745.729, 783561.768 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>Espaces urbanis√©s</td>\n",
              "      <td>1121</td>\n",
              "      <td>Habitat discontinu pavillonnaire dense</td>\n",
              "      <td>POLYGON ((780722.098 6294678.385, 780721.497 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7</td>\n",
              "      <td>Espaces naturels non bois√©s</td>\n",
              "      <td>7100</td>\n",
              "      <td>Landes et fourr√©s</td>\n",
              "      <td>POLYGON ((786841.696 6288153.548, 786890.819 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5140</td>\n",
              "      <td>Prairies</td>\n",
              "      <td>POLYGON ((789960.810 6292452.935, 790102.874 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5131</td>\n",
              "      <td>Cultures annuelles</td>\n",
              "      <td>POLYGON ((779098.925 6290704.206, 779110.710 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5121</td>\n",
              "      <td>Espaces libres urbains</td>\n",
              "      <td>POLYGON ((775231.972 6278064.325, 775253.847 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5121</td>\n",
              "      <td>Espaces libres urbains</td>\n",
              "      <td>POLYGON ((781809.791 6279916.092, 781849.165 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2</td>\n",
              "      <td>Surfaces industrielles ou commerciales et infr...</td>\n",
              "      <td>2211</td>\n",
              "      <td>R√©seau routier principal et espaces associ√©s</td>\n",
              "      <td>POLYGON ((784997.550 6286524.234, 784953.998 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>Espaces urbanis√©s</td>\n",
              "      <td>1141</td>\n",
              "      <td>Habitat discontinu collectif</td>\n",
              "      <td>POLYGON ((773931.461 6284459.010, 773948.589 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5</td>\n",
              "      <td>Espaces agricoles</td>\n",
              "      <td>5121</td>\n",
              "      <td>Espaces libres urbains</td>\n",
              "      <td>POLYGON ((742462.145 6250502.972, 742492.161 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>4</td>\n",
              "      <td>Espaces r√©cr√©atifs</td>\n",
              "      <td>4121</td>\n",
              "      <td>Autres parcs et jardins</td>\n",
              "      <td>POLYGON ((773469.289 6276654.713, 773467.563 6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    c2021_niv1                                         lib21_niv1  c2021_niv4  \\\n",
              "0            7                        Espaces naturels non bois√©s        7820   \n",
              "1            5                                  Espaces agricoles        5121   \n",
              "2            5                                  Espaces agricoles        5121   \n",
              "3            8                                                Eau        8220   \n",
              "4            5                                  Espaces agricoles        5121   \n",
              "5            5                                  Espaces agricoles        5221   \n",
              "6            5                                  Espaces agricoles        5221   \n",
              "7            6                                     Espaces bois√©s        6110   \n",
              "8            8                                                Eau        8300   \n",
              "9            5                                  Espaces agricoles        5140   \n",
              "10           8                                                Eau        8210   \n",
              "11           5                                  Espaces agricoles        5131   \n",
              "12           5                                  Espaces agricoles        5140   \n",
              "13           2  Surfaces industrielles ou commerciales et infr...        2111   \n",
              "14           5                                  Espaces agricoles        5211   \n",
              "15           1                                  Espaces urbanis√©s        1121   \n",
              "16           7                        Espaces naturels non bois√©s        7100   \n",
              "17           5                                  Espaces agricoles        5140   \n",
              "18           5                                  Espaces agricoles        5131   \n",
              "19           5                                  Espaces agricoles        5121   \n",
              "20           5                                  Espaces agricoles        5121   \n",
              "21           2  Surfaces industrielles ou commerciales et infr...        2211   \n",
              "22           1                                  Espaces urbanis√©s        1141   \n",
              "23           5                                  Espaces agricoles        5121   \n",
              "24           4                                 Espaces r√©cr√©atifs        4121   \n",
              "\n",
              "                                      lib21_niv4  \\\n",
              "0                               Marais maritimes   \n",
              "1                         Espaces libres urbains   \n",
              "2                         Espaces libres urbains   \n",
              "3              Plans d'eau et lagunes littorales   \n",
              "4                         Espaces libres urbains   \n",
              "5                        Vergers en exploitation   \n",
              "6                        Vergers en exploitation   \n",
              "7                  Feuillus m√©sophiles dominants   \n",
              "8                        Mer, oc√©an et estuaires   \n",
              "9                                       Prairies   \n",
              "10                             Plans d‚Äôeau douce   \n",
              "11                            Cultures annuelles   \n",
              "12                                      Prairies   \n",
              "13                           Zones industrielles   \n",
              "14                        Vignes en exploitation   \n",
              "15        Habitat discontinu pavillonnaire dense   \n",
              "16                             Landes et fourr√©s   \n",
              "17                                      Prairies   \n",
              "18                            Cultures annuelles   \n",
              "19                        Espaces libres urbains   \n",
              "20                        Espaces libres urbains   \n",
              "21  R√©seau routier principal et espaces associ√©s   \n",
              "22                  Habitat discontinu collectif   \n",
              "23                        Espaces libres urbains   \n",
              "24                       Autres parcs et jardins   \n",
              "\n",
              "                                             geometry  \n",
              "0   POLYGON ((742269.535 6248240.552, 742250.300 6...  \n",
              "1   POLYGON ((783953.823 6291883.226, 783966.394 6...  \n",
              "2   POLYGON ((781205.235 6284279.038, 781260.980 6...  \n",
              "3   POLYGON ((780145.613 6277024.020, 780063.022 6...  \n",
              "4   POLYGON ((758879.856 6272901.789, 758892.140 6...  \n",
              "5   POLYGON ((785921.828 6282821.166, 785954.456 6...  \n",
              "6   POLYGON ((760408.100 6274080.600, 760403.112 6...  \n",
              "7   POLYGON ((744068.463 6254143.414, 744011.575 6...  \n",
              "8   POLYGON ((757311.864 6255758.885, 757309.379 6...  \n",
              "9   POLYGON ((758260.437 6271489.652, 758257.173 6...  \n",
              "10  POLYGON ((750614.887 6272923.560, 750660.415 6...  \n",
              "11  POLYGON ((762779.796 6271812.527, 762813.156 6...  \n",
              "12  POLYGON ((756135.058 6270198.722, 756115.697 6...  \n",
              "13  POLYGON ((770134.885 6275211.804, 770099.111 6...  \n",
              "14  POLYGON ((783495.201 6299745.729, 783561.768 6...  \n",
              "15  POLYGON ((780722.098 6294678.385, 780721.497 6...  \n",
              "16  POLYGON ((786841.696 6288153.548, 786890.819 6...  \n",
              "17  POLYGON ((789960.810 6292452.935, 790102.874 6...  \n",
              "18  POLYGON ((779098.925 6290704.206, 779110.710 6...  \n",
              "19  POLYGON ((775231.972 6278064.325, 775253.847 6...  \n",
              "20  POLYGON ((781809.791 6279916.092, 781849.165 6...  \n",
              "21  POLYGON ((784997.550 6286524.234, 784953.998 6...  \n",
              "22  POLYGON ((773931.461 6284459.010, 773948.589 6...  \n",
              "23  POLYGON ((742462.145 6250502.972, 742492.161 6...  \n",
              "24  POLYGON ((773469.289 6276654.713, 773467.563 6...  "
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Collect landcover fields of interest\n",
        "clc_21_niv4_3m_gdf = clc_3m_gdf[\n",
        "    [\"c2021_niv1\", \"lib21_niv1\", \"c2021_niv4\", \"lib21_niv4\", \"geometry\"]\n",
        "]\n",
        "clc_21_niv4_3m_gdf.head(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "N68Ye09mSuqC",
        "outputId": "05d34689-c661-4f2a-bfcd-468fec28bed3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/gaetan/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>geometry</th>\n",
              "      <th>eunis_niv1_label</th>\n",
              "      <th>CODE_EUNIS_niv1</th>\n",
              "      <th>c2021_niv4</th>\n",
              "      <th>c2021_niv1</th>\n",
              "      <th>area_ha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>POLYGON ((742269.535 6248240.552, 742250.300 6...</td>\n",
              "      <td>2</td>\n",
              "      <td>B</td>\n",
              "      <td>7820</td>\n",
              "      <td>7</td>\n",
              "      <td>0.005211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>POLYGON ((767352.525 6268848.993, 767361.873 6...</td>\n",
              "      <td>2</td>\n",
              "      <td>B</td>\n",
              "      <td>7820</td>\n",
              "      <td>7</td>\n",
              "      <td>0.113166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>POLYGON ((763211.640 6263361.392, 763236.168 6...</td>\n",
              "      <td>2</td>\n",
              "      <td>B</td>\n",
              "      <td>7820</td>\n",
              "      <td>7</td>\n",
              "      <td>1.269219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>POLYGON ((766041.394 6268039.741, 766037.300 6...</td>\n",
              "      <td>2</td>\n",
              "      <td>B</td>\n",
              "      <td>7820</td>\n",
              "      <td>7</td>\n",
              "      <td>5.224858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>POLYGON ((768466.461 6265323.085, 768466.452 6...</td>\n",
              "      <td>2</td>\n",
              "      <td>B</td>\n",
              "      <td>7820</td>\n",
              "      <td>7</td>\n",
              "      <td>0.041889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            geometry  eunis_niv1_label  \\\n",
              "0  POLYGON ((742269.535 6248240.552, 742250.300 6...                 2   \n",
              "1  POLYGON ((767352.525 6268848.993, 767361.873 6...                 2   \n",
              "2  POLYGON ((763211.640 6263361.392, 763236.168 6...                 2   \n",
              "3  POLYGON ((766041.394 6268039.741, 766037.300 6...                 2   \n",
              "4  POLYGON ((768466.461 6265323.085, 768466.452 6...                 2   \n",
              "\n",
              "  CODE_EUNIS_niv1  c2021_niv4  c2021_niv1   area_ha  \n",
              "0               B        7820           7  0.005211  \n",
              "1               B        7820           7  0.113166  \n",
              "2               B        7820           7  1.269219  \n",
              "3               B        7820           7  5.224858  \n",
              "4               B        7820           7  0.041889  "
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Add CLC:EUNIS mapping + Stats\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "eunis_mapping_df = pd.read_excel(\"./data_ns/CORINE_LAND_COVER_MONTPELLIER.xlsx\")\n",
        "\n",
        "map_df = eunis_mapping_df[[\"c2021_niv4\", \"eunis_niv1_label\"]]\n",
        "gdf = clc_21_niv4_3m_gdf.merge(eunis_mapping_df, on=\"c2021_niv4\", suffixes=(\"\", \"_map\"))\n",
        "eunis_niv1_3m_gdf = gdf[\n",
        "    [\"geometry\", \"eunis_niv1_label\", \"CODE_EUNIS_niv1\", \"c2021_niv4\", \"c2021_niv1\"]\n",
        "]\n",
        "eunis_niv1_3m_gdf[\"area_ha\"] = eunis_niv1_3m_gdf[\"geometry\"].area / 10**4\n",
        "eunis_niv1_3m_gdf.reset_index()\n",
        "eunis_niv1_3m_gdf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhJ8sm_ySuqD",
        "outputId": "e43a8725-ceed-45c6-c7ff-57b76cec96f8"
      },
      "outputs": [],
      "source": [
        "# Uncomment this if you want to export spreadsheet with some metrics\n",
        "\n",
        "# import os\n",
        "\n",
        "# if not os.path.exists(f\"{WORKDIR}/data/export\"):\n",
        "#     os.makedirs(f\"{WORKDIR}/data/export\")\n",
        "\n",
        "# df = eunis_niv1_3m_gdf.groupby(\n",
        "#     [\"eunis_niv1_label\", \"CODE_EUNIS_niv1\", \"c2021_niv4\", \"c2021_niv1\"]\n",
        "# )[\"eunis_niv1_label\"].count()\n",
        "# df.to_csv(f\"{WORKDIR}/data/export/eunis1-clc4_2021_3m.csv\")\n",
        "# df.to_excel(f\"{WORKDIR}/data/export/eunis1-clc4_2021_3m.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7RhTf8SvSuqD",
        "outputId": "6ece83d8-57f3-46c5-aaa9-fc5b92df8128"
      },
      "outputs": [],
      "source": [
        "# Uncomment the following lines if you want EUNIS classes metric by city - Excel export only\n",
        "\n",
        "\n",
        "# boundaries = gpd.read_file(\n",
        "#     f\"{WORKDIR}/data/test/MMM_MMM_PolesZonage_0/MMM_MMM_PolesZonage.shp\", crs=\"EPSG:2154\"\n",
        "# )\n",
        "\n",
        "\n",
        "# def plot_area_and_grid(area_gdf, grid_gdf, title=\"Geoplot 1\"):\n",
        "#     import matplotlib.pyplot as plt\n",
        "\n",
        "#     fig, ax = plt.subplots(figsize=(14, 7))\n",
        "#     area_gdf.plot(ec=\"gray\", fc=\"none\", figsize=(10, 10), ax=ax)\n",
        "#     grid_gdf.plot(fc=\"none\", ec=\"black\", ax=ax)\n",
        "#     ax.set_title(title)\n",
        "\n",
        "\n",
        "# with pd.ExcelWriter(f\"{WORKDIR}/data/export/eunis1-clc4_2021_3m_classes.xlsx\") as local_writer:\n",
        "#     for row in boundaries.itertuples():\n",
        "#         clipped = eunis_niv1_3m_gdf.clip(row.geometry)\n",
        "#         clipped_2154 = clipped.to_crs(\"EPSG:2154\")\n",
        "#         grid = create_size_based_grid(gdf=clipped_2154)\n",
        "#         plot_area_and_grid(clipped_2154, grid, row.nom)\n",
        "#         local_summary_df = clipped_2154.groupby(\n",
        "#             [\"eunis_niv1_label\", \"CODE_EUNIS_niv1\"]\n",
        "#         )[\"area_ha\"].sum()\n",
        "#         local_summary_df.to_excel(\n",
        "#             local_writer, sheet_name=f\"N={len(grid)} -> {row.nom}\"\n",
        "#         )\n",
        "\n",
        "# with pd.ExcelWriter(f\"{WORKDIR}/data/export/eunis1-clc4_2021_3m.xlsx\") as global_writer:\n",
        "#     global_summary_df = eunis_niv1_3m_gdf.groupby(\n",
        "#         [\"eunis_niv1_label\", \"CODE_EUNIS_niv1\"]\n",
        "#     )[\"area_ha\"].sum()\n",
        "#     global_summary_df.to_excel(global_writer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06qh-h8QSuqD",
        "outputId": "393e8ff9-8b73-4273-f3e5-1b04b4cce518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['CASTELNAU-LE-LEZ', 'MONTPELLIER', 'PEROLS', 'CASTRIES', 'BAILLARGUES', 'BEAULIEU', 'COURNONSEC', 'JACOU', 'CLAPIERS', 'COURNONTERRAL', 'LAVERUNE', 'FABREGUES', 'RESTINCLIERES', 'GRABELS', 'SAINT-BRES', 'JUVIGNAC', 'VENDARGUES', 'LATTES', 'LE CRES', 'MONTFERRIER-SUR-LEZ', 'MONTAUD', 'SAINT-GENIES-DES-MOURGUES', 'MURVIEL-LES-MONTPELLIER', 'SAINT-DREZERY', 'PIGNAN', 'SAUSSAN', 'PRADES-LE-LEZ', 'SUSSARGUES', \"SAINT-GEORGES-D'ORQUES\", 'SAINT-JEAN-DE-VEDAS', 'VILLENEUVE-LES-MAGUELONE']\n"
          ]
        }
      ],
      "source": [
        "boundaries = gpd.read_file(\n",
        "    \"./data/test/MMM_MMM_PolesZonage_0/MMM_MMM_PolesZonage.shp\", crs=\"EPSG:2154\"\n",
        ")\n",
        "cities = [row.nom for row in boundaries.itertuples()]\n",
        "print(cities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>codcomm</th>\n",
              "      <th>nom</th>\n",
              "      <th>POLE</th>\n",
              "      <th>geometry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>340057</td>\n",
              "      <td>CASTELNAU-LE-LEZ</td>\n",
              "      <td>Vall√©e du Lez</td>\n",
              "      <td>POLYGON ((771484.390 6283324.480, 771515.720 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>340172</td>\n",
              "      <td>MONTPELLIER</td>\n",
              "      <td>Montpellier</td>\n",
              "      <td>POLYGON ((765145.010 6282066.590, 765146.010 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>340198</td>\n",
              "      <td>PEROLS</td>\n",
              "      <td>Littoral</td>\n",
              "      <td>POLYGON ((775110.540 6276463.730, 775120.800 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>340058</td>\n",
              "      <td>CASTRIES</td>\n",
              "      <td>Cadoule et B√©range</td>\n",
              "      <td>POLYGON ((775699.370 6290396.570, 775814.740 6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>340022</td>\n",
              "      <td>BAILLARGUES</td>\n",
              "      <td>Cadoule et B√©range</td>\n",
              "      <td>POLYGON ((779570.840 6284434.860, 779691.590 6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  codcomm               nom                POLE  \\\n",
              "0  340057  CASTELNAU-LE-LEZ       Vall√©e du Lez   \n",
              "1  340172       MONTPELLIER         Montpellier   \n",
              "2  340198            PEROLS            Littoral   \n",
              "3  340058          CASTRIES  Cadoule et B√©range   \n",
              "4  340022       BAILLARGUES  Cadoule et B√©range   \n",
              "\n",
              "                                            geometry  \n",
              "0  POLYGON ((771484.390 6283324.480, 771515.720 6...  \n",
              "1  POLYGON ((765145.010 6282066.590, 765146.010 6...  \n",
              "2  POLYGON ((775110.540 6276463.730, 775120.800 6...  \n",
              "3  POLYGON ((775699.370 6290396.570, 775814.740 6...  \n",
              "4  POLYGON ((779570.840 6284434.860, 779691.590 6...  "
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "boundaries.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlsUNUAYSuqE"
      },
      "source": [
        "## Training data preparation utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_h5_for_chunk(\n",
        "    h5_filename=\"./datasets/training.h5\",\n",
        "    images_path=\"./datasets/images\",\n",
        "    masks_path=\"./datasets/masks\",\n",
        "):\n",
        "    from PIL import Image\n",
        "    from pathlib import Path\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import rasterio\n",
        "    from rasterio.plot import reshape_as_image\n",
        "\n",
        "    IMAGES_ORTHO_DIR = f\"{images_path}/ortho\"\n",
        "    IMAGES_IRC_DIR = f\"{images_path}/irc\"\n",
        "    IMAGES_RGBN_DIR = f\"{images_path}/rgbn\"\n",
        "    MASKS_DIR = masks_path\n",
        "\n",
        "    def save_h5_dataset(filename, images_ortho, images_irc, images_training, masks):\n",
        "        import h5py\n",
        "        import os\n",
        "\n",
        "        # ---- Create h5 file\n",
        "        with h5py.File(filename, \"w\") as f:\n",
        "            f.create_dataset(\"ortho\", data=images_ortho)\n",
        "            f.create_dataset(\"irc\", data=images_irc)\n",
        "            f.create_dataset(\"training\", data=images_training)\n",
        "            f.create_dataset(\"masks\", data=masks)\n",
        "\n",
        "        # ---- done\n",
        "        size = os.path.getsize(filename) / (1024 * 1024)\n",
        "        print(\n",
        "            f\"Dataset : {filename}  shape_masks : {masks.shape} shape_training : {images_training.shape} size : {size} Mo   (saved)\"\n",
        "        )\n",
        "\n",
        "    image_ortho_names = []\n",
        "    for file in Path(IMAGES_ORTHO_DIR).glob(\"*.tif\"):\n",
        "        fileName = Path(file).stem + \".tif\"\n",
        "        image_ortho_names.append(os.path.join(IMAGES_ORTHO_DIR, fileName))\n",
        "        image_ortho_names.sort()\n",
        "\n",
        "    image_irc_names = []\n",
        "    for file in Path(IMAGES_IRC_DIR).glob(\"*.tif\"):\n",
        "        fileName = Path(file).stem + \".tif\"\n",
        "        image_irc_names.append(os.path.join(IMAGES_IRC_DIR, fileName))\n",
        "        image_irc_names.sort()\n",
        "\n",
        "    image_rgbn_names = []\n",
        "    for file in Path(IMAGES_RGBN_DIR).glob(\"*.tif\"):\n",
        "        fileName = Path(file).stem + \".tif\"\n",
        "        image_rgbn_names.append(os.path.join(IMAGES_RGBN_DIR, fileName))\n",
        "        image_rgbn_names.sort()\n",
        "\n",
        "    mask_names = []\n",
        "    for file in Path(MASKS_DIR).glob(\"*.tif\"):\n",
        "        fileName = Path(file).stem + \".tif\"\n",
        "        mask_names.append(os.path.join(MASKS_DIR, fileName))\n",
        "    mask_names.sort()\n",
        "\n",
        "    images_ortho = [np.asarray(Image.open(image)) for image in image_ortho_names]\n",
        "    images_irc = [np.asarray(Image.open(image)) for image in image_irc_names]\n",
        "    images_rgbn = [np.asarray(Image.open(image)) for image in image_rgbn_names]\n",
        "    masks = [reshape_as_image(rasterio.open(mask).read()) for mask in mask_names]\n",
        "    image_ortho_datasset = np.array(images_ortho)\n",
        "    image_irc_datasset = np.array(images_irc)\n",
        "    image_rgbn_datasset = np.array(images_rgbn)\n",
        "    mask_dataset = np.array(masks)\n",
        "    # H5_FILE = \"/content/drive/MyDrive/data/data_Montpellier/training_09.h5\"\n",
        "    save_h5_dataset(\n",
        "        h5_filename,\n",
        "        image_ortho_datasset,\n",
        "        image_irc_datasset,\n",
        "        image_rgbn_datasset,\n",
        "        mask_dataset,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "##### 0 ######\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_0.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (1, 256, 256, 1) shape_training : (1, 256, 256, 4) size : 0.31640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_1.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (2, 256, 256, 1) shape_training : (2, 256, 256, 4) size : 0.62890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_2.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (3, 256, 256, 1) shape_training : (3, 256, 256, 4) size : 0.94140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_3.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (4, 256, 256, 1) shape_training : (4, 256, 256, 4) size : 1.25390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_4.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (5, 256, 256, 1) shape_training : (5, 256, 256, 4) size : 1.56640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_5.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (6, 256, 256, 1) shape_training : (6, 256, 256, 4) size : 1.87890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_6.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (7, 256, 256, 1) shape_training : (7, 256, 256, 4) size : 2.19140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_7.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (8, 256, 256, 1) shape_training : (8, 256, 256, 4) size : 2.50390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_8.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (9, 256, 256, 1) shape_training : (9, 256, 256, 4) size : 2.81640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq0/masks/mask_9.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq0/training.h5  shape_masks : (10, 256, 256, 1) shape_training : (10, 256, 256, 4) size : 3.12890625 Mo   (saved)\n",
            "##### 1 ######\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_10.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (1, 256, 256, 1) shape_training : (1, 256, 256, 4) size : 0.31640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_11.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (2, 256, 256, 1) shape_training : (2, 256, 256, 4) size : 0.62890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_12.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (3, 256, 256, 1) shape_training : (3, 256, 256, 4) size : 0.94140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_13.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (4, 256, 256, 1) shape_training : (4, 256, 256, 4) size : 1.25390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_14.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (5, 256, 256, 1) shape_training : (5, 256, 256, 4) size : 1.56640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_15.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (6, 256, 256, 1) shape_training : (6, 256, 256, 4) size : 1.87890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_16.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (7, 256, 256, 1) shape_training : (7, 256, 256, 4) size : 2.19140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_17.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (8, 256, 256, 1) shape_training : (8, 256, 256, 4) size : 2.50390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_18.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (9, 256, 256, 1) shape_training : (9, 256, 256, 4) size : 2.81640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq1/masks/mask_19.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq1/training.h5  shape_masks : (10, 256, 256, 1) shape_training : (10, 256, 256, 4) size : 3.12890625 Mo   (saved)\n",
            "##### 2 ######\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_20.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (1, 256, 256, 1) shape_training : (1, 256, 256, 4) size : 0.31640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_21.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (2, 256, 256, 1) shape_training : (2, 256, 256, 4) size : 0.62890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_22.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (3, 256, 256, 1) shape_training : (3, 256, 256, 4) size : 0.94140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_23.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (4, 256, 256, 1) shape_training : (4, 256, 256, 4) size : 1.25390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_24.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (5, 256, 256, 1) shape_training : (5, 256, 256, 4) size : 1.56640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_25.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (6, 256, 256, 1) shape_training : (6, 256, 256, 4) size : 1.87890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_26.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (7, 256, 256, 1) shape_training : (7, 256, 256, 4) size : 2.19140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_27.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (8, 256, 256, 1) shape_training : (8, 256, 256, 4) size : 2.50390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_28.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (9, 256, 256, 1) shape_training : (9, 256, 256, 4) size : 2.81640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq2/masks/mask_29.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq2/training.h5  shape_masks : (10, 256, 256, 1) shape_training : (10, 256, 256, 4) size : 3.12890625 Mo   (saved)\n",
            "##### 3 ######\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_30.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (1, 256, 256, 1) shape_training : (1, 256, 256, 4) size : 0.31640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_31.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (2, 256, 256, 1) shape_training : (2, 256, 256, 4) size : 0.62890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_32.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (3, 256, 256, 1) shape_training : (3, 256, 256, 4) size : 0.94140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_33.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (4, 256, 256, 1) shape_training : (4, 256, 256, 4) size : 1.25390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_34.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (5, 256, 256, 1) shape_training : (5, 256, 256, 4) size : 1.56640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_35.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (6, 256, 256, 1) shape_training : (6, 256, 256, 4) size : 1.87890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_36.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (7, 256, 256, 1) shape_training : (7, 256, 256, 4) size : 2.19140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_37.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (8, 256, 256, 1) shape_training : (8, 256, 256, 4) size : 2.50390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_38.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (9, 256, 256, 1) shape_training : (9, 256, 256, 4) size : 2.81640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq3/masks/mask_39.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq3/training.h5  shape_masks : (10, 256, 256, 1) shape_training : (10, 256, 256, 4) size : 3.12890625 Mo   (saved)\n",
            "##### 4 ######\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_40.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (1, 256, 256, 1) shape_training : (1, 256, 256, 4) size : 0.31640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_41.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (2, 256, 256, 1) shape_training : (2, 256, 256, 4) size : 0.62890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_42.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (3, 256, 256, 1) shape_training : (3, 256, 256, 4) size : 0.94140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_43.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (4, 256, 256, 1) shape_training : (4, 256, 256, 4) size : 1.25390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_44.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (5, 256, 256, 1) shape_training : (5, 256, 256, 4) size : 1.56640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_45.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (6, 256, 256, 1) shape_training : (6, 256, 256, 4) size : 1.87890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_46.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (7, 256, 256, 1) shape_training : (7, 256, 256, 4) size : 2.19140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_47.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (8, 256, 256, 1) shape_training : (8, 256, 256, 4) size : 2.50390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_48.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (9, 256, 256, 1) shape_training : (9, 256, 256, 4) size : 2.81640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq4/masks/mask_49.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq4/training.h5  shape_masks : (10, 256, 256, 1) shape_training : (10, 256, 256, 4) size : 3.12890625 Mo   (saved)\n",
            "##### 5 ######\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_50.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (1, 256, 256, 1) shape_training : (1, 256, 256, 4) size : 0.31640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_51.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (2, 256, 256, 1) shape_training : (2, 256, 256, 4) size : 0.62890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_52.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (3, 256, 256, 1) shape_training : (3, 256, 256, 4) size : 0.94140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_53.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (4, 256, 256, 1) shape_training : (4, 256, 256, 4) size : 1.25390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_54.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (5, 256, 256, 1) shape_training : (5, 256, 256, 4) size : 1.56640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_55.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (6, 256, 256, 1) shape_training : (6, 256, 256, 4) size : 1.87890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_56.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (7, 256, 256, 1) shape_training : (7, 256, 256, 4) size : 2.19140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_57.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (8, 256, 256, 1) shape_training : (8, 256, 256, 4) size : 2.50390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_58.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (9, 256, 256, 1) shape_training : (9, 256, 256, 4) size : 2.81640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq5/masks/mask_59.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq5/training.h5  shape_masks : (10, 256, 256, 1) shape_training : (10, 256, 256, 4) size : 3.12890625 Mo   (saved)\n",
            "##### 6 ######\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq6/masks/mask_60.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq6/training.h5  shape_masks : (1, 256, 256, 1) shape_training : (1, 256, 256, 4) size : 0.31640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq6/masks/mask_61.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq6/training.h5  shape_masks : (2, 256, 256, 1) shape_training : (2, 256, 256, 4) size : 0.62890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq6/masks/mask_62.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq6/training.h5  shape_masks : (3, 256, 256, 1) shape_training : (3, 256, 256, 4) size : 0.94140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq6/masks/mask_63.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq6/training.h5  shape_masks : (4, 256, 256, 1) shape_training : (4, 256, 256, 4) size : 1.25390625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq6/masks/mask_64.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq6/training.h5  shape_masks : (5, 256, 256, 1) shape_training : (5, 256, 256, 4) size : 1.56640625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq6/masks/mask_65.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq6/training.h5  shape_masks : (6, 256, 256, 1) shape_training : (6, 256, 256, 4) size : 1.87890625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq6/masks/mask_66.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq6/training.h5  shape_masks : (7, 256, 256, 1) shape_training : (7, 256, 256, 4) size : 2.19140625 Mo   (saved)\n",
            "./3m-ai/grid_256px_11_classes/datasets/h5/seq6/masks/mask_67.tif\n",
            "Dataset : ./3m-ai/grid_256px_11_classes/datasets/h5/seq6/training.h5  shape_masks : (8, 256, 256, 1) shape_training : (8, 256, 256, 4) size : 2.50390625 Mo   (saved)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[68], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m clipped[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meunis_niv1_label\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m clipped[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meunis_niv1_label\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m mask_path \u001b[38;5;241m=\u001b[39m labels_to_mask_with_geocube(\n\u001b[1;32m     11\u001b[0m     clipped, index, out_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/masks\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m (ortho_path, irc_path, train_path) \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_4_band_training_raster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclipped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mseq_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(mask_path)\n\u001b[1;32m     17\u001b[0m set_h5_for_chunk(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/training.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/images\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/masks\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m )\n",
            "Cell \u001b[0;32mIn[53], line 49\u001b[0m, in \u001b[0;36mcreate_4_band_training_raster\u001b[0;34m(gdf, index, out_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./datasets/images\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     47\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./datasets/images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m (ortho_path, ortho_time, d_ortho_url) \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_image_from_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mortho_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_path\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m (irc_path, irc_time, d_irc_url) \u001b[38;5;241m=\u001b[39m download_image_from_url(\n\u001b[1;32m     53\u001b[0m     url\u001b[38;5;241m=\u001b[39mirc_url, index\u001b[38;5;241m=\u001b[39mindex, out_path\u001b[38;5;241m=\u001b[39mout_path\n\u001b[1;32m     54\u001b[0m )\n\u001b[1;32m     55\u001b[0m train_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/rgbn\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "Cell \u001b[0;32mIn[51], line 72\u001b[0m, in \u001b[0;36mdownload_image_from_url\u001b[0;34m(url, index, out_path, default_images_folder)\u001b[0m\n\u001b[1;32m     70\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(out_dir)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/urllib3/response.py:934\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 934\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m    937\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/urllib3/response.py:877\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 877\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/urllib3/response.py:812\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    809\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 812\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/3m-ai-dataprep-env/lib/python3.10/site-packages/urllib3/response.py:797\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "for k, g in grid_3m.groupby(np.arange(len(grid_3m)) // 10):\n",
        "    print(f\"##### {k} ######\")\n",
        "    seq_folder = f\"{WORKDIR}/datasets/h5/seq{k}\"\n",
        "\n",
        "    for index, row in g.iterrows():\n",
        "        clipped = eunis_niv1_3m_gdf.clip(row.geometry)\n",
        "        clipped[\"eunis_niv1_label\"] = clipped[\"eunis_niv1_label\"].astype(\"int8\")\n",
        "        mask_path = labels_to_mask_with_geocube(\n",
        "            clipped, index, out_path=f\"{seq_folder}/masks\"\n",
        "        )\n",
        "        (ortho_path, irc_path, train_path) = create_4_band_training_raster(\n",
        "            clipped, index, out_path=f\"{seq_folder}/images\"\n",
        "        )\n",
        "        print(mask_path)\n",
        "        set_h5_for_chunk(\n",
        "            f\"{seq_folder}/training_{k}.h5\",\n",
        "            f\"{seq_folder}/images\",\n",
        "            f\"{seq_folder}/masks\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIwq4zwW7epK"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3m-ai-dataprep-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
